# Migration: Gemini ‚Üí OpenAI

## T·ªïng quan
ƒê√£ chuy·ªÉn ƒë·ªïi ho√†n to√†n t·ª´ **Google Gemini AI** sang **OpenAI GPT** cho h·ªá th·ªëng chatbot.

---

## Thay ƒë·ªïi ch√≠nh

### 1. **Dependencies**
```bash
# ƒê√£ g·ª°
- @google/generative-ai

# ƒê√£ c√†i
+ openai
```

### 2. **Environment Variables (.env)**
```env
# Kh√¥ng d√πng n·ªØa (c√≥ th·ªÉ x√≥a)
GEMINI_API_KEY=...
GEMINI_MODEL_NAME=...

# ƒêang s·ª≠ d·ª•ng
OPENAI_API_KEY=sk-proj-...
OPENAI_MODEL_NAME=gpt-4o-mini
```

### 3. **Files ƒë√£ thay ƒë·ªïi**

#### ‚úÖ `src/config/environment.config.js`
```diff
- GEMINI_API_KEY: process.env.GEMINI_API_KEY,
- GEMINI_MODEL_NAME: process.env.GEMINI_MODEL_NAME,
+ OPENAI_API_KEY: process.env.OPENAI_API_KEY,
+ OPENAI_MODEL_NAME: process.env.OPENAI_MODEL_NAME,
```

#### ‚úÖ `src/config/chatbot.config.js`
```diff
- import { GoogleGenerativeAI } from '@google/generative-ai'
- // FUNCTION DECLARATIONS FOR GEMINI
+ // FUNCTION DECLARATIONS FOR OPENAI

AI: {
-   API_KEY: env.GEMINI_API_KEY,
-   MODEL_NAME: env.GEMINI_MODEL_NAME || 'gemini-1.5-pro',
+   API_KEY: env.OPENAI_API_KEY,
+   MODEL_NAME: env.OPENAI_MODEL_NAME || 'gpt-4o-mini',
    GENERATION_CONFIG: {
      temperature: 0.7,
-     topP: 0.9,
-     topK: 40,
-     maxOutputTokens: 2048,
+     max_tokens: 2048,
    }
}
```

#### ‚úÖ `src/modules/chatbot/service/chatbot.service.js`
```diff
- // AI-Powered Chatbot with Gemini Function Calling
- import { handleFunctionCallingFlow } from './gemini.service.js'
+ // AI-Powered Chatbot with OpenAI Function Calling
+ import { handleFunctionCallingFlow } from './openai.service.js'

- console.log('ü§ñ Calling Gemini AI...')
+ console.log('ü§ñ Calling OpenAI...')
```

#### ‚úÖ `src/modules/chatbot/controller/chatbot.controller.js`
```diff
- version: '2.0 - Gemini Function Calling',
+ version: '2.0 - OpenAI Function Calling',
```

#### üÜï `src/modules/chatbot/service/openai.service.js` (NEW FILE)
File m·ªõi thay th·∫ø `gemini.service.js` v·ªõi c√°c t√≠nh nƒÉng:
- Function calling v·ªõi OpenAI
- Context management (10 messages g·∫ßn nh·∫•t)
- Error handling
- Health check

---

## API Models

### OpenAI Models ƒë∆∞·ª£c h·ªó tr·ª£:
| Model | Use Case | Cost |
|-------|----------|------|
| `gpt-4o-mini` | **Recommended** - Fast, cheap, good quality | Lowest |
| `gpt-4o` | Best quality, slower | Medium |
| `gpt-4-turbo` | High quality | High |
| `gpt-3.5-turbo` | Fastest, cheapest (legacy) | Lowest |

**Hi·ªán t·∫°i ƒëang d√πng:** `gpt-4o-mini`

---

## S·ª± kh√°c bi·ªát gi·ªØa Gemini v√† OpenAI

### 1. **Message Format**
```javascript
// Gemini
{
  role: 'user' | 'model',
  parts: [{ text: '...' }]
}

// OpenAI
{
  role: 'user' | 'assistant' | 'system',
  content: '...'
}
```

### 2. **Function Calling Format**
```javascript
// Gemini
tools: [{
  functionDeclarations: [{ name, description, parameters }]
}]

// OpenAI
tools: [{
  type: 'function',
  function: { name, description, parameters }
}]
```

### 3. **Function Response**
```javascript
// Gemini
response.functionCalls ‚Üí array of function calls
Send back: [{ functionResponse: { name, response } }]

// OpenAI
message.tool_calls ‚Üí array of tool calls
Send back: { role: 'tool', tool_call_id, content }
```

### 4. **Context Management**
```javascript
// Gemini
model.startChat({ history: [...messages] })

// OpenAI
client.chat.completions.create({
  messages: [
    { role: 'system', content: SYSTEM_PROMPT },
    ...history,
    { role: 'user', content: userMessage }
  ]
})
```

---

## Testing

### Test chatbot:
```bash
# Anonymous message
POST http://localhost:3000/api/chatbot/anonymous/message
{
  "message": "Gym c√≥ g√≥i n√†o?"
}

# Authenticated message
POST http://localhost:3000/api/chatbot/message/USER_ID
{
  "message": "G√≥i t·∫≠p c·ªßa t√¥i"
}

# Health check
GET http://localhost:3000/api/chatbot/health
```

### Expected response:
```json
{
  "success": true,
  "response": {
    "content": "THE GYM c√≥ 3 g√≥i membership:\n\nüí™ G√≥i Basic...",
    "type": "ai_response"
  },
  "conversationId": "...",
  "timestamp": "..."
}
```

---

## Troubleshooting

### Error: "Invalid API key"
```bash
# Ki·ªÉm tra .env
OPENAI_API_KEY=sk-proj-...  # Ph·∫£i b·∫Øt ƒë·∫ßu v·ªõi sk-proj- ho·∫∑c sk-
```

### Error: "Model not found"
```bash
# S·ª≠a model name trong .env
OPENAI_MODEL_NAME=gpt-4o-mini  # Ho·∫∑c gpt-4o, gpt-4-turbo
```

### Error: "Rate limit exceeded"
OpenAI free tier c√≥ gi·ªõi h·∫°n:
- 3 requests/minute (RPM)
- 200 requests/day (RPD)

**Gi·∫£i ph√°p:**
1. Upgrade OpenAI account
2. Ho·∫∑c th√™m retry logic v·ªõi exponential backoff
3. Ho·∫∑c gi·∫£m t·∫ßn su·∫•t test

---

## Cost Comparison

### Gemini API (Free tier):
- ‚úÖ 15 requests/minute
- ‚úÖ 1,500 requests/day
- ‚úÖ Free forever

### OpenAI API (Free tier):
- ‚ö†Ô∏è 3 requests/minute
- ‚ö†Ô∏è 200 requests/day
- ‚ö†Ô∏è $5 free credit (expires after 3 months)

### Recommendation:
N·∫øu b·∫°n lo v·ªÅ cost:
1. D√πng `gpt-4o-mini` (r·∫ª nh·∫•t)
2. Implement caching ƒë·ªÉ gi·∫£m API calls
3. Rate limit ph√≠a frontend
4. Ho·∫∑c quay l·∫°i Gemini (free h∆°n nhi·ªÅu)

---

## Rollback Plan

N·∫øu mu·ªën quay l·∫°i Gemini:

```bash
# 1. C√†i l·∫°i Gemini package
npm install @google/generative-ai

# 2. Restore files t·ª´ backup ho·∫∑c git
git checkout HEAD~1 src/modules/chatbot/service/gemini.service.js
git checkout HEAD~1 src/modules/chatbot/service/chatbot.service.js
git checkout HEAD~1 src/config/chatbot.config.js
git checkout HEAD~1 src/config/environment.config.js

# 3. Update .env
GEMINI_API_KEY=...
GEMINI_MODEL_NAME=gemini-1.5-pro

# 4. X√≥a openai.service.js
rm src/modules/chatbot/service/openai.service.js

# 5. Uninstall OpenAI
npm uninstall openai
```

---

## Completed ‚úÖ

- ‚úÖ Installed OpenAI package
- ‚úÖ Updated environment config
- ‚úÖ Created openai.service.js
- ‚úÖ Updated chatbot.service.js
- ‚úÖ Updated chatbot.config.js
- ‚úÖ Updated chatbot.controller.js
- ‚úÖ Removed Google Generative AI package
- ‚úÖ Updated default model to gpt-4o-mini

**H·ªá th·ªëng chatbot gi·ªù ƒëang ch·∫°y ho√†n to√†n tr√™n OpenAI!** üéâ
